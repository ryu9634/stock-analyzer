"""
ê¸‰ë“± ì˜ˆì¸¡ê¸° v4 - Low Cap US Stock Surge Detector
í•µì‹¬: ì‹œì´ì´ ë‚®ê³  ë³€ë™ì„±ì´ ë†’ì€ ë¯¸êµ­ ì†Œí˜•ì£¼ì—ì„œ ê¸‰ë“± ì§ì „ ì¢…ëª©ì„ ì°¾ëŠ”ë‹¤

[ë¶„ì„ ì¹´í…Œê³ ë¦¬]
1. ë³€ë™ì„± í”„ë¡œíŒŒì¼ (15%) â€” ATR%, ì—­ì‚¬ì ë³€ë™ì„±, ìœ ë™ë¹„ìœ¨, ìƒëŒ€ê±°ë˜ëŸ‰, ìº”ë“¤ë²”ìœ„
2. ë§¤ì§‘ ê°ì§€ (35%) â€” OBV ë‹¤ì´ë²„ì „ìŠ¤, Chaikin MF, ê±°ë˜ëŸ‰ ê±´ì¡°â†’ê¸‰ì¦, A/D Line
3. ì°¨íŠ¸ íŒ¨í„´ (30%) â€” ë³¼ë¦°ì €ìŠ¤í€´ì¦ˆ, ì €í•­ì„ ì ‘ê·¼, ì‚¼ê°ìˆ˜ë ´, ì»µì•¤í•¸ë“¤, ì´í‰ì„ ë°€ì§‘,
                       ì €ì ìƒìŠ¹, ë² ì´ìŠ¤ëŒíŒŒ, í¬ì¼“í”¼ë´‡, ê°­ë¶„ì„, VWAPíšŒë³µ, ìƒëŒ€ê°•ë„
4. ê¸°ìˆ  ëª¨ë©˜í…€ (20%) â€” RSI, MACD, ëª¨ë©˜í…€
5. ë³´ë„ˆìŠ¤ â€” ì£¼ë´‰ì¶”ì„¸ ì •ë ¬, ìˆìŠ¤í€´ì¦ˆ, ì„¹í„° ìƒëŒ€ê°•ë„

[v4 ì‹ ê·œ]
- ì£¼ë´‰ ë©€í‹°íƒ€ì„í”„ë ˆì„ ë¶„ì„ & ë³´ë„ˆìŠ¤
- ì‹œê·¸ë„ ì§€ì†ì„± ì¶”ì  (ì‹ ê·œ vs Nì¼ ì—°ì†)
- ê³¼ê±° ì‹œê·¸ë„ ì ì¤‘ë¥  ìë™ ê³„ì‚°
- ìˆ ì´ììœ¨ & ìˆìŠ¤í€´ì¦ˆ ê°ì§€
- ì‹¤ì  ë°œí‘œ ê·¼ì ‘ ê²½ê³ 
- ì„¹í„° ìƒëŒ€ê°•ë„ ë³´ë„ˆìŠ¤
- ë¯¸ë‹ˆì°¨íŠ¸ ìŠ¤íŒŒí¬ë¼ì¸ ë°ì´í„°
- OBV ë²¡í„°í™” ì„±ëŠ¥ ìµœì í™”
- Nasdaq API ì¬ì‹œë„ ë¡œì§
- ë°ì´í„° ì‚¬ì´ì¦ˆ ìµœì í™” (ìƒìœ„ 500 ìƒì„¸, ë‚˜ë¨¸ì§€ ìš”ì•½)
"""

import yfinance as yf
import pandas as pd
import numpy as np
import json
import os
import html
import requests
import warnings
import time
from datetime import datetime, timezone, timedelta
from concurrent.futures import ThreadPoolExecutor, as_completed

warnings.filterwarnings("ignore")

# ====== ì„¤ì • ======
TELEGRAM_BOT_TOKEN = os.environ.get("TELEGRAM_BOT_TOKEN", "").strip()
TELEGRAM_CHAT_ID = os.environ.get("TELEGRAM_CHAT_ID", "").strip()

MAX_MARKET_CAP = 2_000_000_000  # $2B
MIN_VOLUME = 100_000
BATCH_SIZE = 500
MAX_WORKERS = 5


def format_market_cap(mcap):
    if not mcap:
        return "N/A"
    if mcap >= 1_000_000_000:
        return f"${mcap / 1_000_000_000:.1f}B"
    elif mcap >= 1_000_000:
        return f"${mcap / 1_000_000:.0f}M"
    return f"${mcap:,.0f}"


# ====== ì¢…ëª© ìˆ˜ì§‘ ======

class UniverseFetcher:
    """ë¯¸êµ­ ì†Œí˜•ì£¼ ìœ ë‹ˆë²„ìŠ¤ ìˆ˜ì§‘"""

    EXTRA_TICKERS = [
        "PL", "RDW", "RKLB", "LUNR", "ASTS", "MNTS", "BKSY", "SATL", "SPCE",
        "SMCI", "SOUN", "BBAI", "IREN", "CLSK", "APLD",
        "SMR", "NNE", "OKLO",
        "IONQ", "RGTI", "QUBT",
        "CRSP", "NTLA", "BEAM", "EDIT",
        "SOFI", "AFRM", "UPST", "NU",
        "HIMS", "DUOL", "CAVA", "TOST",
    ]

    BENCHMARK_TICKERS = ["SPY", "QQQ", "IWM"]

    @staticmethod
    def _parse_market_cap(s):
        if not s or s == "N/A" or s == "":
            return None
        s = s.replace("$", "").replace(",", "").strip()
        try:
            if s.endswith("B"):
                return float(s[:-1]) * 1_000_000_000
            elif s.endswith("M"):
                return float(s[:-1]) * 1_000_000
            elif s.endswith("T"):
                return float(s[:-1]) * 1_000_000_000_000
            else:
                return float(s)
        except ValueError:
            return None

    @staticmethod
    def fetch_nasdaq_screener(max_market_cap=MAX_MARKET_CAP):
        """Nasdaq Screener APIë¡œ ì†Œí˜•ì£¼ ìˆ˜ì§‘ â€” ì¬ì‹œë„ ë¡œì§ + ì„¹í„°/ì—…ì¢… í¬í•¨"""
        metadata = {}
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        }
        offset = 0
        limit = 200
        total = None
        max_retries = 3

        while True:
            url = (
                f"https://api.nasdaq.com/api/screener/stocks"
                f"?tableonly=true&limit={limit}&offset={offset}"
            )
            success = False
            for attempt in range(max_retries):
                try:
                    resp = requests.get(url, headers=headers, timeout=30)
                    data = resp.json()
                    rows = data["data"]["table"]["rows"]
                    if total is None:
                        total = int(data["data"]["totalrecords"])
                        print(f"  ğŸ“¡ Nasdaq screener: {total}ê°œ ìƒì¥ ì¢…ëª©")

                    for row in rows:
                        symbol = row.get("symbol", "").strip()
                        name = row.get("name", symbol).strip()
                        mcap_str = row.get("marketCap", "")
                        mcap = UniverseFetcher._parse_market_cap(mcap_str)
                        sector = row.get("sector", "").strip()
                        industry = row.get("industry", "").strip()

                        if (symbol
                            and mcap is not None
                            and 0 < mcap <= max_market_cap
                            and not any(c in symbol for c in ['^', '/', '.'])
                        ):
                            metadata[symbol] = {
                                "name": name,
                                "market_cap": mcap,
                                "sector": sector,
                                "industry": industry,
                            }

                    success = True
                    break

                except Exception as e:
                    if attempt < max_retries - 1:
                        wait = 2 ** attempt
                        print(f"  âš ï¸ Nasdaq API ì¬ì‹œë„ {attempt+1}/{max_retries} ({wait}ì´ˆ í›„): {e}")
                        time.sleep(wait)
                    else:
                        print(f"  âš ï¸ Nasdaq API ì˜¤ë¥˜ (offset {offset}): {e}")

            if not success and total is None:
                break

            offset += limit
            if total is not None and offset >= total:
                break
            time.sleep(0.3)

        print(f"  âœ… í•„í„°ë§ ì™„ë£Œ: {len(metadata)}ê°œ (ì‹œì´ < ${max_market_cap/1e9:.0f}B)")
        return metadata

    @staticmethod
    def _fallback_wikipedia():
        """í´ë°±: Wikipediaì—ì„œ S&P500 + NASDAQ100"""
        tickers = set()
        try:
            tables = pd.read_html("https://en.wikipedia.org/wiki/List_of_S%26P_500_companies")
            sp500 = tables[0]["Symbol"].str.replace(".", "-", regex=False).tolist()
            tickers.update(sp500)
            print(f"  âœ… S&P 500: {len(sp500)}ì¢…ëª©")
        except Exception as e:
            print(f"  âš ï¸ S&P 500 ë¡œë“œ ì‹¤íŒ¨: {e}")
        try:
            tables = pd.read_html("https://en.wikipedia.org/wiki/Nasdaq-100")
            for t in tables:
                if "Ticker" in t.columns:
                    tickers.update(t["Ticker"].tolist())
                    break
        except Exception as e:
            print(f"  âš ï¸ NASDAQ 100 ë¡œë“œ ì‹¤íŒ¨: {e}")
        return list(tickers)

    @staticmethod
    def get_universe():
        """ë©”ì¸ ì§„ì…ì : Nasdaq API â†’ í´ë°± â†’ ì¶”ê°€ì¢…ëª©. (tickers, metadata) ë°˜í™˜"""
        metadata = {}

        api_meta = UniverseFetcher.fetch_nasdaq_screener()
        if len(api_meta) > 100:
            metadata.update(api_meta)
        else:
            print("  âš ï¸ Nasdaq API ì‹¤íŒ¨, Wikipedia í´ë°± ì‚¬ìš©")
            fb_tickers = UniverseFetcher._fallback_wikipedia()
            for t in fb_tickers:
                metadata[t] = {"name": t, "market_cap": None, "sector": "", "industry": ""}

        for t in UniverseFetcher.EXTRA_TICKERS:
            if t not in metadata:
                metadata[t] = {"name": t, "market_cap": None, "sector": "", "industry": ""}

        tickers = sorted(metadata.keys())
        print(f"  ğŸ“Š ì´ ìœ ë‹ˆë²„ìŠ¤: {len(tickers)}ì¢…ëª©")
        return tickers, metadata


# ====== ë³€ë™ì„± ë¶„ì„ ======

class VolatilityAnalyzer:
    """ë³€ë™ì„± í”„ë¡œíŒŒì¼ â€” ê¸‰ë“± ê°€ëŠ¥ì„±ì´ ë†’ì€ íŠ¹ì„± ì¸¡ì •"""

    @staticmethod
    def atr_percent(high, low, close, period=14):
        """ATR%: ì¼ì¼ ë³€ë™ì„± í¬ê¸°"""
        if len(close) < period + 1:
            return 0, "ë°ì´í„° ë¶€ì¡±"
        tr1 = high - low
        tr2 = (high - close.shift(1)).abs()
        tr3 = (low - close.shift(1)).abs()
        tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
        atr = tr.rolling(period).mean()
        atr_pct = (atr / close * 100).iloc[-1]
        if pd.isna(atr_pct):
            return 50, "N/A"
        if atr_pct > 8:    return 95, f"ATR:{atr_pct:.1f}% ê·¹í•œë³€ë™"
        elif atr_pct > 5:  return 80, f"ATR:{atr_pct:.1f}% ê³ ë³€ë™"
        elif atr_pct > 3:  return 65, f"ATR:{atr_pct:.1f}% ì¤‘ê°„"
        elif atr_pct > 1.5: return 40, f"ATR:{atr_pct:.1f}% ì €ë³€ë™"
        return 20, f"ATR:{atr_pct:.1f}% ë§¤ìš°ë‚®ìŒ"

    @staticmethod
    def historical_volatility(close, period=20):
        """ì—­ì‚¬ì  ë³€ë™ì„±: ì—°í™˜ì‚° ë¡œê·¸ìˆ˜ìµë¥  í‘œì¤€í¸ì°¨"""
        if len(close) < period + 1:
            return 0, "ë°ì´í„° ë¶€ì¡±"
        log_ret = np.log(close / close.shift(1)).dropna()
        if len(log_ret) < period:
            return 50, "N/A"
        hvol = log_ret.iloc[-period:].std() * np.sqrt(252) * 100
        if hvol > 100:   return 95, f"HV:{hvol:.0f}% ê·¹í•œ"
        elif hvol > 70:  return 80, f"HV:{hvol:.0f}% ë§¤ìš°ë†’ìŒ"
        elif hvol > 45:  return 65, f"HV:{hvol:.0f}% ë†’ìŒ"
        elif hvol > 25:  return 45, f"HV:{hvol:.0f}% ë³´í†µ"
        return 20, f"HV:{hvol:.0f}% ë‚®ìŒ"

    @staticmethod
    def float_ratio(info):
        """ìœ ë™ë¹„ìœ¨: ë‚®ì„ìˆ˜ë¡ ê¸‰ë“± ì‹œ í­ë°œì """
        float_shares = info.get("floatShares")
        shares_out = info.get("sharesOutstanding")
        if not float_shares or not shares_out or shares_out == 0:
            return 50, "N/A", None
        ratio = float_shares / shares_out
        if ratio < 0.3:    return 95, f"Float:{ratio:.0%} ê·¹ì†Œ", ratio
        elif ratio < 0.5:  return 75, f"Float:{ratio:.0%} ë‚®ìŒ", ratio
        elif ratio < 0.7:  return 55, f"Float:{ratio:.0%} ë³´í†µ", ratio
        elif ratio < 0.85: return 35, f"Float:{ratio:.0%} ë†’ìŒ", ratio
        return 20, f"Float:{ratio:.0%} ë§¤ìš°ë†’ìŒ", ratio

    @staticmethod
    def relative_volume(volume, info):
        """ìƒëŒ€ê±°ë˜ëŸ‰: ìµœê·¼ ê±°ë˜ëŸ‰ / í‰ê·  ê±°ë˜ëŸ‰"""
        if len(volume) < 20:
            return 0, "ë°ì´í„° ë¶€ì¡±"
        recent_avg = volume.iloc[-3:].mean()
        avg_20d = volume.iloc[-20:].mean()
        if avg_20d == 0:
            return 50, "N/A"
        rvol = recent_avg / avg_20d
        avg_vol = info.get("averageVolume")
        if avg_vol and avg_vol > 0:
            rvol = max(rvol, recent_avg / avg_vol)
        if rvol > 3:     return 95, f"RVol:{rvol:.1f}x í­ì¦"
        elif rvol > 2:   return 80, f"RVol:{rvol:.1f}x ê¸‰ì¦"
        elif rvol > 1.5: return 65, f"RVol:{rvol:.1f}x ì¦ê°€"
        elif rvol > 1:   return 45, f"RVol:{rvol:.1f}x ë³´í†µ"
        return 25, f"RVol:{rvol:.1f}x ê°ì†Œ"

    @staticmethod
    def candle_range(high, low, close, period=10):
        """ìº”ë“¤ ë²”ìœ„: í‰ê·  ìº”ë“¤ í¬ê¸° (ê³ ê°€-ì €ê°€)/ì¢…ê°€"""
        if len(close) < period:
            return 0, "ë°ì´í„° ë¶€ì¡±"
        body_pct = ((high - low) / close * 100).iloc[-period:].mean()
        if pd.isna(body_pct):
            return 50, "N/A"
        if body_pct > 8:    return 90, f"Range:{body_pct:.1f}% ë„“ìŒ"
        elif body_pct > 5:  return 70, f"Range:{body_pct:.1f}% í°í¸"
        elif body_pct > 3:  return 50, f"Range:{body_pct:.1f}% ë³´í†µ"
        return 25, f"Range:{body_pct:.1f}% ì¢ìŒ"


# ====== ë§¤ì§‘ ê°ì§€ ======

class AccumulationDetector:
    """ë§¤ì§‘ ê°ì§€ ì—”ì§„"""

    @staticmethod
    def calc_obv(close, volume):
        """ë²¡í„°í™”ëœ OBV ê³„ì‚° (ê¸°ì¡´ ë£¨í”„ ëŒ€ë¹„ 10x+ ë¹ ë¦„)"""
        direction = np.sign(close.diff()).fillna(0)
        return (direction * volume).cumsum()

    @staticmethod
    def obv_divergence(close, volume):
        """OBV ë‹¤ì´ë²„ì „ìŠ¤: ê°€ê²© íš¡ë³´/í•˜ë½ + OBV ìƒìŠ¹ = ë§¤ì§‘"""
        if len(close) < 30:
            return 0, "ë°ì´í„° ë¶€ì¡±"
        obv = AccumulationDetector.calc_obv(close, volume)
        price_slope = np.polyfit(range(20), close.iloc[-20:].values, 1)[0]
        obv_slope = np.polyfit(range(20), obv.iloc[-20:].values, 1)[0]
        price_chg = price_slope / close.iloc[-20] * 100
        obv_norm = obv_slope / (abs(obv.iloc[-20:]).mean() + 1)

        if price_chg < 0.5 and obv_norm > 0:
            strength = min(100, abs(obv_norm) * 500 + abs(price_chg) * 10)
            if price_chg < -1:
                strength = min(100, strength * 1.3)
            return min(100, strength), f"ê°€ê²©{price_chg:+.1f}% OBVâ†‘"
        elif price_chg > 1 and obv_norm > 0:
            return 40, "ë™ë°˜ ìƒìŠ¹"
        return 15, "ë§¤ì§‘ ë¯¸ê°ì§€"

    @staticmethod
    def chaikin_mf(high, low, close, volume, period=20):
        """Chaikin Money Flow: ìê¸ˆ ìœ ì… ê°•ë„"""
        if len(close) < period:
            return 0, "N/A"
        mfm = ((close - low) - (high - close)) / (high - low + 1e-10)
        mfv = mfm * volume
        cmf = mfv.rolling(period).sum() / volume.rolling(period).sum()
        val = cmf.iloc[-1]
        if pd.isna(val):
            return 50, "N/A"
        if val > 0.15:   return 95, f"CMF:{val:.2f} ê°•í•œë§¤ì§‘"
        elif val > 0.05: return 75, f"CMF:{val:.2f} ë§¤ì§‘"
        elif val > -0.05: return 50, f"CMF:{val:.2f} ì¤‘ë¦½"
        elif val > -0.15: return 25, f"CMF:{val:.2f} ë§¤ë„ì••ë ¥"
        return 10, f"CMF:{val:.2f} ê°•í•œë§¤ë„"

    @staticmethod
    def volume_dryup_spike(volume, period=20):
        """ê±°ë˜ëŸ‰ ê±´ì¡° í›„ ê¸‰ì¦ = ì„¸ë ¥ ì§„ì…"""
        if len(volume) < period + 5:
            return 0, "ë°ì´í„° ë¶€ì¡±"
        dry_avg = volume.iloc[-(period+5):-5].mean()
        recent_avg = volume.iloc[-3:].mean()
        if dry_avg == 0:
            return 0, "N/A"
        full_avg = volume.iloc[-period:].mean()
        dryness = dry_avg / full_avg if full_avg > 0 else 1
        spike = recent_avg / dry_avg

        if dryness < 0.7 and spike > 2:
            return min(100, 60 + spike * 10), f"ê±´ì¡°â†’ê¸‰ì¦ {spike:.1f}x"
        elif spike > 1.5:
            return min(85, 50 + spike * 8), f"ê±°ë˜ëŸ‰â†‘ {spike:.1f}x"
        return 20, f"í‰ì´ {spike:.1f}x"

    @staticmethod
    def ad_line(high, low, close, volume):
        """A/D Line: ì¢…ê°€ ìœ„ì¹˜ ê¸°ë°˜ ë§¤ì§‘/ë¶„ì‚°"""
        if len(close) < 20:
            return 0, "ë°ì´í„° ë¶€ì¡±"
        clv = ((close - low) - (high - close)) / (high - low + 1e-10)
        ad = (clv * volume).cumsum()
        ad_slope = np.polyfit(range(20), ad.iloc[-20:].values, 1)[0]
        price_slope = np.polyfit(range(20), close.iloc[-20:].values, 1)[0]
        ad_trend = ad_slope / (abs(ad.iloc[-20:]).mean() + 1)
        price_trend = price_slope / close.iloc[-20] * 100

        if ad_trend > 0 and price_trend < 0.5:
            return min(90, 60 + abs(ad_trend) * 200), "A/Dâ†‘ ê°€ê²©â†’ ë§¤ì§‘"
        elif ad_trend > 0:
            return 55, "A/Dâ†‘ ë™ë°˜ìƒìŠ¹"
        return 20, "A/Dâ†“ ë¶„ì‚°"


# ====== ì°¨íŠ¸ íŒ¨í„´ ======

class PatternDetector:
    """ëŒíŒŒ ì§ì „ íŒ¨í„´ ê°ì§€"""

    @staticmethod
    def bollinger_squeeze(close, period=20):
        """ë³¼ë¦°ì €ë°´ë“œ ìŠ¤í€´ì¦ˆ: ë°´ë“œ ê·¹ë„ë¡œ ì¢ì•„ì§ â†’ í­ë°œ ì§ì „"""
        if len(close) < period + 10:
            return 0, "ë°ì´í„° ë¶€ì¡±"
        sma = close.rolling(period).mean()
        std = close.rolling(period).std()
        bw = (std / sma * 100).dropna()
        if len(bw) < 10:
            return 0, "ë°ì´í„° ë¶€ì¡±"
        curr = bw.iloc[-1]
        avg = bw.iloc[-60:].mean() if len(bw) >= 60 else bw.mean()
        ratio = curr / avg if avg > 0 else 1

        if ratio < 0.4:   return 95, f"ê·¹í•œìŠ¤í€´ì¦ˆ {ratio:.0%}"
        elif ratio < 0.6: return 80, f"ê°•í•œìŠ¤í€´ì¦ˆ {ratio:.0%}"
        elif ratio < 0.8: return 60, f"ìŠ¤í€´ì¦ˆì§„í–‰ {ratio:.0%}"
        return 30, f"ì¼ë°˜ {ratio:.0%}"

    @staticmethod
    def resistance_approach(high, close):
        """ì €í•­ì„  ì ‘ê·¼: ì—¬ëŸ¬ë²ˆ ë§ê³  ë‚´ë ¤ì˜¨ ê°€ê²©ëŒ€ì— ì¬ì ‘ê·¼"""
        if len(close) < 60:
            return 0, "ë°ì´í„° ë¶€ì¡±"
        current = close.iloc[-1]
        peak = high.iloc[-60:].max()
        dist = (peak - current) / current * 100
        zone = peak * 0.98
        touches = (high.iloc[-60:] >= zone).sum()

        if dist < 2 and touches >= 2:
            return 90, f"ì €í•­ì„  {dist:.1f}% (í„°ì¹˜{touches})"
        elif dist < 3 and touches >= 2:
            return 75, f"ì ‘ê·¼ {dist:.1f}%"
        elif dist < 5:
            return 55, f"ê·¼ì²˜ {dist:.1f}%"
        return 25, f"ë¨¼ê±°ë¦¬ {dist:.1f}%"

    @staticmethod
    def triangle_convergence(high, low, close):
        """ì‚¼ê°ìˆ˜ë ´: ê³ ì â†“ + ì €ì â†‘ = ì—ë„ˆì§€ ì¶•ì """
        if len(close) < 30:
            return 0, "ë°ì´í„° ë¶€ì¡±"
        seg = [(-30, -20), (-20, -10), (-10, None)]
        highs = [high.iloc[s:e].max() for s, e in seg]
        lows = [low.iloc[s:e].min() for s, e in seg]
        h_fall = highs[2] < highs[1] < highs[0]
        l_rise = lows[2] > lows[1] > lows[0]
        r1, r3 = highs[0] - lows[0], highs[2] - lows[2]
        conv = r3 / r1 if r1 > 0 else 1

        if h_fall and l_rise and conv < 0.6:
            return 90, f"ì‚¼ê°ìˆ˜ë ´ ë²”ìœ„{conv:.0%}"
        elif (h_fall or l_rise) and conv < 0.7:
            return 65, f"ë¶€ë¶„ìˆ˜ë ´ {conv:.0%}"
        return 20, "ìˆ˜ë ´ ì—†ìŒ"

    @staticmethod
    def cup_and_handle(close, volume):
        """ì»µì•¤í•¸ë“¤: Uì ë°”ë‹¥ í›„ ì†Œí­ ëˆŒë¦¼"""
        if len(close) < 40:
            return 0, "ë°ì´í„° ë¶€ì¡±"
        r40 = close.iloc[-40:]
        min_pos = r40.values.argmin()
        if not (10 < min_pos < 30):
            return 20, "ì»µ ë¯¸í˜•ì„±"
        bottom = r40.iloc[min_pos]
        left = r40.iloc[:5].mean()
        right = r40.iloc[-5:].mean()
        rim_diff = abs(left - right) / left * 100
        depth = (left - bottom) / left * 100
        handle_val = (r40.iloc[-10:].max() - close.iloc[-1]) / r40.iloc[-10:].max() * 100

        if rim_diff < 5 and 5 < depth < 30 and 0 < handle_val < 8:
            return 85, f"ì»µì•¤í•¸ë“¤ ê¹Šì´{depth:.0f}%"
        elif rim_diff < 8 and depth > 3:
            return 50, "ì»µ í˜•ì„± ì¤‘"
        return 15, "íŒ¨í„´ ì—†ìŒ"

    @staticmethod
    def ma_tightening(close):
        """ì´í‰ì„  ë°€ì§‘: 5/10/20/50ì„  ëª¨ì„ â†’ ë°©í–¥ì„± í­ë°œ"""
        if len(close) < 50:
            return 0, "ë°ì´í„° ë¶€ì¡±"
        mas = [close.iloc[-n:].mean() for n in [5, 10, 20, 50]]
        curr = close.iloc[-1]
        spread = (max(mas) - min(mas)) / curr * 100
        above = sum(1 for m in mas if curr > m)

        if spread < 2:   score, label = 90, f"ê·¹í•œë°€ì§‘ {spread:.1f}%"
        elif spread < 4: score, label = 70, f"ë°€ì§‘ {spread:.1f}%"
        elif spread < 6: score, label = 50, f"ë³´í†µ {spread:.1f}%"
        else:            score, label = 20, f"ë¶„ì‚° {spread:.1f}%"
        if above == 4:
            score = min(100, score + 10)
            label += " ì •ë°°ì—´"
        return score, label

    @staticmethod
    def higher_lows(low):
        """ì—°ì† ì €ì  ìƒìŠ¹: ìš°ìƒí–¥ ê¸°ë°˜ í™•ì¸"""
        if len(low) < 20:
            return 0, "ë°ì´í„° ë¶€ì¡±"
        lows = [low.iloc[s:s+5].min() for s in range(-20, 0, 5)]
        rising = sum(1 for i in range(len(lows)-1) if lows[i] < lows[i+1])
        if rising >= 3:
            return 85, f"ì €ì  ì—°ì†â†‘ {rising+1}êµ¬ê°„"
        elif rising >= 2:
            return 60, f"ì €ì  ìƒìŠ¹ {rising}êµ¬ê°„"
        return 25, "ì €ì  ë¯¸ì•½"

    # ====== ì‹ ê·œ íŒ¨í„´ ======

    @staticmethod
    def base_breakout(close, volume, period=20):
        """ë² ì´ìŠ¤ ëŒíŒŒ: ì¢ì€ íš¡ë³´ êµ¬ê°„ ëŒíŒŒ + ê±°ë˜ëŸ‰ í™•ëŒ€"""
        if len(close) < period + 5:
            return 0, "ë°ì´í„° ë¶€ì¡±"
        base = close.iloc[-(period+5):-5]
        base_range = (base.max() - base.min()) / base.mean() * 100
        current = close.iloc[-1]
        base_high = base.max()
        breakout_pct = (current - base_high) / base_high * 100

        base_vol = volume.iloc[-(period+5):-5].mean()
        recent_vol = volume.iloc[-3:].mean()
        vol_expansion = recent_vol / base_vol if base_vol > 0 else 1

        if base_range < 8 and breakout_pct > 0 and vol_expansion > 1.5:
            return min(100, int(80 + vol_expansion * 5)), f"ëŒíŒŒ! ë²”ìœ„:{base_range:.0f}% vol:{vol_expansion:.1f}x"
        elif base_range < 10 and breakout_pct > -1:
            return 65, f"ëŒíŒŒ ê·¼ì ‘ ë²”ìœ„:{base_range:.0f}%"
        elif base_range < 12:
            return 45, f"íš¡ë³´ ì¤‘ ë²”ìœ„:{base_range:.0f}%"
        return 20, f"ë² ì´ìŠ¤ ì—†ìŒ {base_range:.0f}%"

    @staticmethod
    def pocket_pivot(close, volume):
        """í¬ì¼“ í”¼ë´‡: ìƒìŠ¹ì¼ ê±°ë˜ëŸ‰ > 10ì¼ê°„ ìµœëŒ€ í•˜ë½ì¼ ê±°ë˜ëŸ‰"""
        if len(close) < 12:
            return 0, "ë°ì´í„° ë¶€ì¡±"
        today_up = close.iloc[-1] > close.iloc[-2]
        today_vol = volume.iloc[-1]

        down_vols = []
        for i in range(-11, -1):
            if len(close) > abs(i) and close.iloc[i] < close.iloc[i-1]:
                down_vols.append(volume.iloc[i])

        if not down_vols:
            return 50, "í•˜ë½ì¼ ì—†ìŒ"

        max_down_vol = max(down_vols)

        if today_up and today_vol > max_down_vol:
            ratio = today_vol / max_down_vol
            if len(close) >= 50:
                sma50 = close.iloc[-50:].mean()
                near_ma = abs(close.iloc[-1] - sma50) / sma50 < 0.05
                if near_ma:
                    return min(100, int(80 + ratio * 5)), f"í¬ì¼“í”¼ë´‡+MA50 {ratio:.1f}x"
            return min(90, int(65 + ratio * 5)), f"í¬ì¼“í”¼ë´‡ {ratio:.1f}x"
        elif today_up and today_vol > max_down_vol * 0.8:
            return 55, "í¬ì¼“í”¼ë´‡ ê·¼ì ‘"
        return 20, "í¬ì¼“í”¼ë´‡ ì—†ìŒ"

    @staticmethod
    def gap_analysis(open_price, close, high, low):
        """ê°­ ë¶„ì„: ë¯¸ì¶©ì „ ê°­ì—… íŒ¨í„´ (ê°•ì„¸)"""
        if len(close) < 5:
            return 0, "ë°ì´í„° ë¶€ì¡±"
        gaps = []
        for i in range(-5, 0):
            if len(close) > abs(i):
                gap_pct = (open_price.iloc[i] - close.iloc[i-1]) / close.iloc[i-1] * 100
                if gap_pct > 1:
                    filled = low.iloc[i:].min() < close.iloc[i-1]
                    gaps.append({"day": i, "pct": gap_pct, "filled": filled})

        unfilled_gaps = [g for g in gaps if not g["filled"]]

        if unfilled_gaps:
            biggest = max(unfilled_gaps, key=lambda g: g["pct"])
            return min(90, int(65 + biggest["pct"] * 5)), f"ë¯¸ì¶©ì „ê°­ +{biggest['pct']:.1f}%"
        elif gaps:
            return 45, f"ê°­ ì¶©ì „ë¨ ({len(gaps)}ê°œ)"
        return 20, "ê°­ ì—†ìŒ"

    @staticmethod
    def vwap_reclaim(high, low, close, volume):
        """VWAP íšŒë³µ: VWAP ì•„ë˜â†’ìœ„ íšŒë³µ"""
        if len(close) < 20:
            return 0, "ë°ì´í„° ë¶€ì¡±"
        period = min(20, len(close))
        typical = (high.iloc[-period:] + low.iloc[-period:] + close.iloc[-period:]) / 3
        cum_tv = (typical * volume.iloc[-period:]).cumsum()
        cum_v = volume.iloc[-period:].cumsum()
        vwap = cum_tv / cum_v

        current_price = close.iloc[-1]
        current_vwap = vwap.iloc[-1]
        yesterday_price = close.iloc[-2]
        yesterday_vwap = vwap.iloc[-2] if len(vwap) >= 2 else current_vwap

        if yesterday_price < yesterday_vwap and current_price > current_vwap:
            pct_above = (current_price - current_vwap) / current_vwap * 100
            return min(90, int(75 + pct_above * 5)), f"VWAP íšŒë³µ +{pct_above:.1f}%"
        elif current_price > current_vwap:
            pct_above = (current_price - current_vwap) / current_vwap * 100
            return 55, f"VWAP ìœ„ +{pct_above:.1f}%"
        else:
            pct_below = (current_vwap - current_price) / current_vwap * 100
            return 25, f"VWAP ì•„ë˜ -{pct_below:.1f}%"

    @staticmethod
    def relative_strength_vs_spy(close, spy_close):
        """ìƒëŒ€ê°•ë„: SPY ëŒ€ë¹„ 5/10/20ì¼ ì´ˆê³¼ìˆ˜ìµ"""
        if len(close) < 20 or spy_close is None or len(spy_close) < 20:
            return 0, "ë°ì´í„° ë¶€ì¡±"

        outperform = 0
        details = []
        for days in [5, 10, 20]:
            if len(close) >= days and len(spy_close) >= days:
                stock_ret = (close.iloc[-1] / close.iloc[-days] - 1) * 100
                spy_ret = (spy_close.iloc[-1] / spy_close.iloc[-days] - 1) * 100
                alpha = stock_ret - spy_ret
                if alpha > 0:
                    outperform += 1
                details.append(f"{days}d:{alpha:+.1f}%")

        if outperform == 3:   return 90, f"RS+++ {' '.join(details)}"
        elif outperform == 2: return 70, f"RS++ {' '.join(details)}"
        elif outperform == 1: return 45, f"RS+ {' '.join(details)}"
        return 20, f"RSì•½ {' '.join(details)}"


# ====== ë©€í‹° íƒ€ì„í”„ë ˆì„ ======

class MultiTimeframeAnalyzer:
    """ì£¼ë´‰ ì¶”ì„¸ ë¶„ì„ â€” ì¼ë´‰ ë°ì´í„°ë¥¼ ì£¼ë´‰ìœ¼ë¡œ ë¦¬ìƒ˜í”Œë§"""

    @staticmethod
    def weekly_trend(close, volume):
        """ì£¼ë´‰ ì¶”ì„¸: 10ì£¼ MA, 4ì£¼ ë³€í™”ìœ¨, ì£¼ë´‰ ê±°ë˜ëŸ‰"""
        if len(close) < 50:
            return 0, "ë°ì´í„° ë¶€ì¡±"

        try:
            wc = close.resample('W').last().dropna()
            wv = volume.resample('W').sum().dropna()
        except Exception:
            return 50, "ë¦¬ìƒ˜í”Œë§ ì‹¤íŒ¨"

        if len(wc) < 10:
            return 50, "ì£¼ë´‰ ë¶€ì¡±"

        ma10 = wc.rolling(10).mean()
        above_ma = False
        if not pd.isna(ma10.iloc[-1]):
            above_ma = wc.iloc[-1] > ma10.iloc[-1]

        w4_ret = 0
        if len(wc) >= 4:
            w4_ret = (wc.iloc[-1] / wc.iloc[-4] - 1) * 100

        wv_ratio = 1
        if len(wv) >= 8:
            recent_wv = wv.iloc[-2:].mean()
            avg_wv = wv.iloc[-8:].mean()
            if avg_wv > 0:
                wv_ratio = recent_wv / avg_wv

        score = 50
        parts = []

        if above_ma:
            score += 15
            parts.append("10ì£¼MAâ†‘")
        else:
            score -= 10
            parts.append("10ì£¼MAâ†“")

        if 0 < w4_ret < 10:
            score += 15
            parts.append(f"4ì£¼+{w4_ret:.1f}%")
        elif w4_ret >= 10:
            score += 5
            parts.append(f"4ì£¼+{w4_ret:.1f}%ê¸‰ë“±")
        elif -5 < w4_ret < 0:
            score += 5
            parts.append(f"4ì£¼{w4_ret:.1f}%ëˆŒë¦¼")
        else:
            score -= 10
            parts.append(f"4ì£¼{w4_ret:.1f}%")

        if wv_ratio > 1.3:
            score += 10
            parts.append(f"ì£¼Vol:{wv_ratio:.1f}x")

        return min(100, max(0, score)), " ".join(parts)


# ====== ì‹œê·¸ë„ ì¶”ì  ======

class SignalTracker:
    """ì‹œê·¸ë„ ì§€ì†ì„± ì¶”ì  + ê³¼ê±° ì ì¤‘ë¥  ê³„ì‚°"""

    def __init__(self, path="data/history.json"):
        self.path = path
        self.history = self._load()

    def _load(self):
        try:
            with open(self.path, encoding="utf-8") as f:
                return json.load(f)
        except Exception:
            return {"snapshots": []}

    def get_persistence(self, ticker):
        """ì´ ì¢…ëª©ì´ ìµœê·¼ ë©°ì¹  ì—°ì† ê´€ì‹¬(55+) ì´ìƒì´ì—ˆëŠ”ì§€"""
        days = 0
        for snap in reversed(self.history["snapshots"]):
            if ticker in snap.get("stocks", {}):
                days += 1
            else:
                break
        return days

    def get_new_signals(self, current_results, threshold=55):
        """ì´ì „ ìŠ¤ëƒ…ìƒ·ì— ì—†ë˜ ìƒˆë¡œìš´ ì‹œê·¸ë„ ì¢…ëª©"""
        if not self.history["snapshots"]:
            return {r["ticker"] for r in current_results if r["total_score"] >= threshold}

        prev_tickers = set(self.history["snapshots"][-1].get("stocks", {}).keys())
        return {
            r["ticker"] for r in current_results
            if r["total_score"] >= threshold and r["ticker"] not in prev_tickers
        }

    def compute_hit_rates(self):
        """ê³¼ê±° 'ê¸‰ë“± ì„ë°•' ì‹œê·¸ë„ì˜ ì‹¤ì œ ì„±ê³¼ ê³„ì‚°"""
        snapshots = self.history["snapshots"]
        if len(snapshots) < 4:
            return None

        periods = {"7d": (5, 9), "14d": (12, 16), "30d": (27, 33)}
        results = {}

        for period_name, (min_days, max_days) in periods.items():
            hits_10 = 0
            hits_5 = 0
            positive = 0
            total = 0
            total_return = 0

            for i, snap in enumerate(snapshots):
                try:
                    snap_date = datetime.strptime(snap["date"], "%Y-%m-%d")
                except (ValueError, KeyError):
                    continue

                for future_snap in snapshots[i+1:]:
                    try:
                        future_date = datetime.strptime(future_snap["date"], "%Y-%m-%d")
                    except (ValueError, KeyError):
                        continue
                    diff = (future_date - snap_date).days

                    if diff < min_days:
                        continue
                    if diff > max_days:
                        break

                    for ticker, data in snap["stocks"].items():
                        if data.get("score", 0) >= 78:
                            future_data = future_snap["stocks"].get(ticker)
                            if future_data and data.get("price", 0) > 0:
                                ret = (future_data["price"] / data["price"] - 1) * 100
                                total += 1
                                total_return += ret
                                if ret >= 10:
                                    hits_10 += 1
                                if ret >= 5:
                                    hits_5 += 1
                                if ret > 0:
                                    positive += 1
                    break
            if total > 0:
                results[period_name] = {
                    "total": total,
                    "hit_10pct": round(hits_10 / total * 100, 1),
                    "hit_5pct": round(hits_5 / total * 100, 1),
                    "positive_pct": round(positive / total * 100, 1),
                    "avg_return": round(total_return / total, 2),
                }

        return results if results else None

    def save_snapshot(self, results):
        """í˜„ì¬ ë¶„ì„ ê²°ê³¼ ìŠ¤ëƒ…ìƒ· ì €ì¥ (ëŒ€ê¸° ì´ìƒë§Œ)"""
        today = datetime.now().strftime("%Y-%m-%d")

        stocks = {}
        for r in results:
            if r["total_score"] >= 40:
                stocks[r["ticker"]] = {
                    "score": r["total_score"],
                    "signal": r["signal"],
                    "price": r["price"],
                }

        self.history["snapshots"] = [
            s for s in self.history["snapshots"] if s.get("date") != today
        ]
        self.history["snapshots"].append({"date": today, "stocks": stocks})
        self.history["snapshots"] = self.history["snapshots"][-90:]

        os.makedirs(os.path.dirname(self.path) or ".", exist_ok=True)
        with open(self.path, "w", encoding="utf-8") as f:
            json.dump(self.history, f, ensure_ascii=False)
        print(f"  ğŸ’¾ ì‹œê·¸ë„ íˆìŠ¤í† ë¦¬ ì €ì¥ ({len(stocks)}ì¢…ëª©, ì´ {len(self.history['snapshots'])}ì¼)")


# ====== ë©”ì¸ ì—”ì§„ ======

class PreSurgePredictor:
    """ê¸‰ë“± ì˜ˆì¸¡ê¸° v4 ë©”ì¸"""

    def __init__(self):
        self.results = []
        self.market_summary = {}
        self.spy_close = None
        self.metadata = {}
        self.signal_tracker = SignalTracker()

    def analyze_stock(self, ticker, hist):
        """ê°œë³„ ì¢…ëª© ë¶„ì„ â€” histëŠ” yf.download()ë¡œ ë°›ì€ DataFrame"""
        if hist is None or hist.empty or len(hist) < 30:
            return None

        meta = self.metadata.get(ticker, {})
        c, h, l, v = hist["Close"], hist["High"], hist["Low"], hist["Volume"]
        o = hist["Open"]

        if c.dropna().empty or len(c.dropna()) < 30:
            return None

        info = meta.get("_info", {})

        # ===== ë³€ë™ì„± í”„ë¡œíŒŒì¼ (15%) =====
        atr_s, atr_d = VolatilityAnalyzer.atr_percent(h, l, c)
        hv_s, hv_d = VolatilityAnalyzer.historical_volatility(c)
        fr_result = VolatilityAnalyzer.float_ratio(info)
        fr_s, fr_d, fr_val = fr_result
        rv_s, rv_d = VolatilityAnalyzer.relative_volume(v, info)
        cr_s, cr_d = VolatilityAnalyzer.candle_range(h, l, c)

        vol_items = [
            {"name": "ATR%",       "score": atr_s, "value": atr_d, "w": 25},
            {"name": "ì—­ì‚¬ì ë³€ë™ì„±", "score": hv_s,  "value": hv_d,  "w": 25},
            {"name": "ìœ ë™ë¹„ìœ¨",    "score": fr_s,  "value": fr_d,  "w": 20},
            {"name": "ìƒëŒ€ê±°ë˜ëŸ‰",  "score": rv_s,  "value": rv_d,  "w": 15},
            {"name": "ìº”ë“¤ë²”ìœ„",    "score": cr_s,  "value": cr_d,  "w": 15},
        ]

        # ===== ë§¤ì§‘ ê°ì§€ (35%) =====
        obv_s, obv_d = AccumulationDetector.obv_divergence(c, v)
        cmf_s, cmf_d = AccumulationDetector.chaikin_mf(h, l, c, v)
        vds_s, vds_d = AccumulationDetector.volume_dryup_spike(v)
        ad_s, ad_d = AccumulationDetector.ad_line(h, l, c, v)

        acc_items = [
            {"name": "OBV ë‹¤ì´ë²„ì „ìŠ¤", "score": obv_s, "value": obv_d, "w": 30},
            {"name": "Chaikin MF",     "score": cmf_s, "value": cmf_d, "w": 25},
            {"name": "ê±°ë˜ëŸ‰ ê±´ì¡°â†’ê¸‰ì¦", "score": vds_s, "value": vds_d, "w": 25},
            {"name": "A/D Line",       "score": ad_s,  "value": ad_d,  "w": 20},
        ]

        # ===== ì°¨íŠ¸ íŒ¨í„´ (30%) =====
        sq_s, sq_d = PatternDetector.bollinger_squeeze(c)
        rs2_s, rs2_d = PatternDetector.resistance_approach(h, c)
        tr_s, tr_d = PatternDetector.triangle_convergence(h, l, c)
        ch_s, ch_d = PatternDetector.cup_and_handle(c, v)
        ma_s, ma_d = PatternDetector.ma_tightening(c)
        hl_s, hl_d = PatternDetector.higher_lows(l)
        bb_s, bb_d = PatternDetector.base_breakout(c, v)
        pp_s, pp_d = PatternDetector.pocket_pivot(c, v)
        ga_s, ga_d = PatternDetector.gap_analysis(o, c, h, l)
        vw_s, vw_d = PatternDetector.vwap_reclaim(h, l, c, v)
        rspy_s, rspy_d = PatternDetector.relative_strength_vs_spy(c, self.spy_close)

        pat_items = [
            {"name": "ë³¼ë¦°ì € ìŠ¤í€´ì¦ˆ",  "score": sq_s,   "value": sq_d,   "w": 12},
            {"name": "ì €í•­ì„  ì ‘ê·¼",     "score": rs2_s,  "value": rs2_d,  "w": 12},
            {"name": "ë² ì´ìŠ¤ ëŒíŒŒ",     "score": bb_s,   "value": bb_d,   "w": 12},
            {"name": "í¬ì¼“ í”¼ë´‡",       "score": pp_s,   "value": pp_d,   "w": 10},
            {"name": "ì‚¼ê°ìˆ˜ë ´",        "score": tr_s,   "value": tr_d,   "w": 8},
            {"name": "ì»µì•¤í•¸ë“¤",        "score": ch_s,   "value": ch_d,   "w": 8},
            {"name": "ì´í‰ì„  ë°€ì§‘",     "score": ma_s,   "value": ma_d,   "w": 8},
            {"name": "ì—°ì† ì €ì â†‘",      "score": hl_s,   "value": hl_d,   "w": 8},
            {"name": "ê°­ ë¶„ì„",         "score": ga_s,   "value": ga_d,   "w": 8},
            {"name": "VWAP íšŒë³µ",       "score": vw_s,   "value": vw_d,   "w": 7},
            {"name": "ìƒëŒ€ê°•ë„ vs SPY", "score": rspy_s, "value": rspy_d, "w": 7},
        ]

        # ===== ê¸°ìˆ  ëª¨ë©˜í…€ (20%) =====
        rsi_s, rsi_d = self._rsi(c)
        macd_s, macd_d = self._macd(c)
        mom_s, mom_d = self._momentum(c)

        tech_items = [
            {"name": "RSI",    "score": rsi_s,  "value": rsi_d,  "w": 35},
            {"name": "MACD",   "score": macd_s, "value": macd_d, "w": 35},
            {"name": "ëª¨ë©˜í…€", "score": mom_s,  "value": mom_d,  "w": 30},
        ]

        # ===== ì£¼ë´‰ ë©€í‹°íƒ€ì„í”„ë ˆì„ =====
        weekly_s, weekly_d = MultiTimeframeAnalyzer.weekly_trend(c, v)

        def wavg(items):
            tw = sum(i["w"] for i in items)
            return sum(i["score"] * i["w"] / tw for i in items)

        vol_avg = wavg(vol_items)
        acc_avg = wavg(acc_items)
        pat_avg = wavg(pat_items)
        tech_avg = wavg(tech_items)

        total = vol_avg * 0.15 + acc_avg * 0.35 + pat_avg * 0.30 + tech_avg * 0.20

        # ë³´ë„ˆìŠ¤
        bonus = 0
        if acc_avg >= 70 and sq_s >= 70:   bonus += 12
        if acc_avg >= 65 and bb_s >= 70:   bonus += 10
        if acc_avg >= 65 and rs2_s >= 70:  bonus += 8
        if vol_avg >= 70 and acc_avg >= 65: bonus += 8
        if pp_s >= 70 and rs2_s >= 65:     bonus += 6
        # ì£¼ë´‰ ì •ë ¬ ë³´ë„ˆìŠ¤
        if weekly_s >= 70:                  bonus += 5
        total = min(100, total + bonus)

        # ì‹œê·¸ë„
        if total >= 78:   sig = "ğŸ”´ ê¸‰ë“± ì„ë°•"
        elif total >= 68: sig = "ğŸŸ  ë§¤ì§‘ ì§„í–‰"
        elif total >= 55: sig = "ğŸŸ¡ ê´€ì‹¬"
        elif total >= 40: sig = "ğŸ”µ ëŒ€ê¸°"
        else:             sig = "âšª ê´€ë§"

        name = html.escape(meta.get("name") or info.get("shortName") or ticker)

        r1d = (c.iloc[-1] / c.iloc[-2] - 1) * 100 if len(c) >= 2 else 0
        r5d = (c.iloc[-1] / c.iloc[-5] - 1) * 100 if len(c) >= 5 else 0
        r20d = (c.iloc[-1] / c.iloc[-20] - 1) * 100 if len(c) >= 20 else 0
        vr = float(v[-3:].mean() / v[-20:].mean()) if len(v) >= 20 and v[-20:].mean() > 0 else 1.0

        # ATR% ì›ì‹œê°’
        atr_pct_val = None
        if len(c) >= 15:
            tr1 = h - l
            tr2 = (h - c.shift(1)).abs()
            tr3 = (l - c.shift(1)).abs()
            tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
            atr_raw = tr.rolling(14).mean()
            atr_pct_val = round(float((atr_raw / c * 100).iloc[-1]), 2) if not pd.isna((atr_raw / c * 100).iloc[-1]) else None

        flags = []
        if acc_avg >= 70 and sq_s >= 70:    flags.append("ğŸ’¥ ë§¤ì§‘+ìŠ¤í€´ì¦ˆ")
        if acc_avg >= 65 and bb_s >= 70:    flags.append("ğŸš€ ë§¤ì§‘+ëŒíŒŒ")
        if obv_s >= 75:                     flags.append("ğŸ•µï¸ OBV ë§¤ì§‘")
        if sq_s >= 80:                      flags.append("ğŸ”¥ ë³€ë™ì„± í­ë°œ ì„ë°•")
        if rs2_s >= 75:                     flags.append("ğŸšª ì €í•­ì„  ëŒíŒŒ ì„ë°•")
        if vds_s >= 75:                     flags.append("âš¡ ê±°ë˜ëŸ‰ ê¸‰ì¦")
        if acc_avg >= 70:                   flags.append("ğŸ“¦ ê°•í•œ ë§¤ì§‘")
        if pp_s >= 70:                      flags.append("ğŸ’ í¬ì¼“ í”¼ë´‡")
        if bb_s >= 70:                      flags.append("ğŸ“Š ë² ì´ìŠ¤ ëŒíŒŒ")
        if vol_avg >= 75:                   flags.append("ğŸŒ‹ ê³ ë³€ë™ì„±")
        if fr_s >= 80:                      flags.append("ğŸ¯ Low Float")
        if weekly_s >= 75:                  flags.append("ğŸ“ˆ ì£¼ë´‰ ì •ë ¬")

        mcap = meta.get("market_cap") or info.get("marketCap")

        # ìŠ¤íŒŒí¬ë¼ì¸ ë°ì´í„° (ìµœê·¼ 30ì¼, 0~100 ì •ê·œí™”)
        spark_len = min(30, len(c))
        spark_raw = c.iloc[-spark_len:].values
        sp_min, sp_max = float(spark_raw.min()), float(spark_raw.max())
        sp_range = sp_max - sp_min if sp_max != sp_min else 1
        sparkline = [round((float(p) - sp_min) / sp_range * 100) for p in spark_raw]

        return {
            "ticker": ticker,
            "name": name,
            "market": "US",
            "price": round(float(c.iloc[-1]), 2),
            "signal": sig,
            "total_score": round(total, 1),
            "volatility_score": round(vol_avg, 1),
            "accum_score": round(acc_avg, 1),
            "pattern_score": round(pat_avg, 1),
            "tech_score": round(tech_avg, 1),
            "weekly_score": round(weekly_s, 1),
            "return_1d": round(r1d, 2),
            "return_5d": round(r5d, 2),
            "return_20d": round(r20d, 2),
            "volume_ratio": round(vr, 2),
            "market_cap": mcap,
            "market_cap_fmt": format_market_cap(mcap),
            "float_ratio": round(fr_val, 2) if fr_val is not None else None,
            "atr_pct": atr_pct_val,
            "sparkline": sparkline,
            "details": {
                "volatility": [{"name": i["name"], "score": i["score"], "value": i["value"]} for i in vol_items],
                "accumulation": [{"name": i["name"], "score": i["score"], "value": i["value"]} for i in acc_items],
                "pattern": [{"name": i["name"], "score": i["score"], "value": i["value"]} for i in pat_items],
                "technical": [{"name": i["name"], "score": i["score"], "value": i["value"]} for i in tech_items],
                "weekly": [{"name": "ì£¼ë´‰ ì¶”ì„¸", "score": round(weekly_s, 1), "value": weekly_d}],
            },
            "sector": html.escape(meta.get("sector", "") or info.get("sector", "")),
            "industry": html.escape(meta.get("industry", "") or info.get("industry", "")),
            "per": info.get("trailingPE"),
            "flags": flags,
            "updated_at": datetime.now(timezone(timedelta(hours=9))).isoformat(),
        }

    def _rsi(self, close, period=14):
        if len(close) < period + 1:
            return 50, "N/A"
        d = close.diff()
        g = d.where(d > 0, 0).rolling(period).mean()
        lo = (-d.where(d < 0, 0)).rolling(period).mean()
        rs = g / lo.replace(0, np.nan)
        rsi = 100 - (100 / (1 + rs))
        v = rsi.iloc[-1]
        if pd.isna(v):
            return 50, "N/A"
        if v < 30:   return 85, f"RSI:{v:.0f} ê³¼ë§¤ë„"
        elif v < 45: return 70, f"RSI:{v:.0f} ë°˜ë“±êµ¬ê°„"
        elif v < 55: return 55, f"RSI:{v:.0f} ì¤‘ë¦½"
        elif v < 70: return 45, f"RSI:{v:.0f} ìƒìŠ¹ì¤‘"
        return 20, f"RSI:{v:.0f} ê³¼ë§¤ìˆ˜"

    def _macd(self, close):
        if len(close) < 26:
            return 50, "N/A"
        macd = close.ewm(span=12).mean() - close.ewm(span=26).mean()
        sig = macd.ewm(span=9).mean()
        h = macd - sig
        if h.iloc[-1] > 0 and h.iloc[-2] <= 0:
            return 90, "ê³¨ë“ í¬ë¡œìŠ¤!"
        elif h.iloc[-1] > 0 and h.iloc[-1] > h.iloc[-2]:
            return 70, "íˆìŠ¤í† ê·¸ë¨â†‘"
        elif h.iloc[-1] > 0:
            return 55, "ì–‘ìˆ˜"
        elif h.iloc[-1] < 0 and h.iloc[-1] > h.iloc[-2]:
            return 60, "ë°˜ë“±ì‹œë„"
        return 30, "ìŒìˆ˜"

    def _momentum(self, close):
        if len(close) < 20:
            return 50, "N/A"
        r5 = (close.iloc[-1] / close.iloc[-5] - 1) * 100
        r10 = (close.iloc[-1] / close.iloc[-10] - 1) * 100
        if 0 < r5 < 3 and r10 > 0:
            return 75, f"ì ì ˆìƒìŠ¹ {r5:+.1f}%"
        elif -3 < r5 < 0 and r10 > 0:
            return 65, f"ëˆŒë¦¼ëª© {r5:+.1f}%"
        elif r5 > 5:
            return 35, f"ì´ë¯¸ìƒìŠ¹ {r5:+.1f}%"
        elif r5 < -5:
            return 40, f"ê¸‰ë½ {r5:+.1f}%"
        return 50, f"íš¡ë³´ {r5:+.1f}%"

    def _bulk_download(self, tickers, period="6mo", chunk_size=500):
        """yf.download()ë¡œ OHLCV ì¼ê´„ ë‹¤ìš´ë¡œë“œ â€” ê°œë³„ í˜¸ì¶œ ëŒ€ë¹„ 10x+ ë¹ ë¦„"""
        all_data = {}
        total_chunks = (len(tickers) + chunk_size - 1) // chunk_size

        for i in range(0, len(tickers), chunk_size):
            chunk = tickers[i:i + chunk_size]
            chunk_num = i // chunk_size + 1
            print(f"  ğŸ“¦ ë‹¤ìš´ë¡œë“œ {chunk_num}/{total_chunks} ({len(chunk)}ì¢…ëª©)...")
            try:
                df = yf.download(
                    chunk, period=period, group_by="ticker",
                    threads=True, progress=False, timeout=30
                )
                if df.empty:
                    continue

                if len(chunk) == 1:
                    t = chunk[0]
                    if not df.empty and len(df) >= 30:
                        all_data[t] = df
                else:
                    for t in chunk:
                        try:
                            ticker_df = df[t].dropna(how="all")
                            if not ticker_df.empty and len(ticker_df) >= 30:
                                all_data[t] = ticker_df
                        except (KeyError, TypeError):
                            pass
            except Exception as e:
                print(f"    âš ï¸ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {e}")

            if i + chunk_size < len(tickers):
                time.sleep(1)

        return all_data

    def _add_sector_bonuses(self, results):
        """ì„¹í„° ìƒëŒ€ê°•ë„ ë³´ë„ˆìŠ¤: ê°™ì€ ì„¹í„° ëŒ€ë¹„ ì´ˆê³¼ ìˆ˜ìµ ì‹œ ê°€ì‚°"""
        sector_returns = {}
        for r in results:
            sector = r.get("sector", "")
            if sector and sector != "N/A" and sector != "":
                if sector not in sector_returns:
                    sector_returns[sector] = []
                sector_returns[sector].append(r["return_5d"])

        sector_avg = {}
        for s, rets in sector_returns.items():
            if len(rets) >= 3:
                sector_avg[s] = np.mean(rets)

        for r in results:
            sector = r.get("sector", "")
            if sector in sector_avg:
                alpha = r["return_5d"] - sector_avg[sector]
                r["sector_alpha"] = round(alpha, 1)
                if alpha > 5:
                    r["total_score"] = min(100, r["total_score"] + 3)
                elif alpha > 2:
                    r["total_score"] = min(100, r["total_score"] + 1)
            else:
                r["sector_alpha"] = None

        print(f"  ğŸ“Š ì„¹í„° ë³´ë„ˆìŠ¤ ì ìš© ({len(sector_avg)}ê°œ ì„¹í„°)")

    def _enrich_top_results(self, results, top_n=100):
        """ìƒìœ„ ì¢…ëª©: ê°œë³„ info ì¡°íšŒ â†’ float ratio, ìˆ ì´ììœ¨, ì‹¤ì ì¼, ì„¹í„° ë³´ê°•"""
        candidates = results[:top_n]
        print(f"\nğŸ” ìƒìœ„ {len(candidates)}ì¢…ëª© ìƒì„¸ ì •ë³´ ì¡°íšŒ ì¤‘...")

        def fetch_info(r):
            try:
                info = yf.Ticker(r["ticker"]).info or {}
                return r["ticker"], info
            except Exception:
                return r["ticker"], {}

        enriched = {}
        with ThreadPoolExecutor(max_workers=5) as ex:
            futs = {ex.submit(fetch_info, r): r["ticker"] for r in candidates}
            for f in as_completed(futs):
                try:
                    ticker, info = f.result()
                    enriched[ticker] = info
                except Exception:
                    pass

        short_count = 0
        earnings_count = 0

        for r in results:
            info = enriched.get(r["ticker"], {})
            if not info:
                continue

            # float ratio ì—…ë°ì´íŠ¸
            fr_s, fr_d, fr_val = VolatilityAnalyzer.float_ratio(info)
            r["float_ratio"] = round(fr_val, 2) if fr_val is not None else r.get("float_ratio")

            # ì„¹í„°/ì‚°ì—… ë³´ê°•
            r["sector"] = html.escape(info.get("sector", r.get("sector", "")))
            r["industry"] = html.escape(info.get("industry", r.get("industry", "")))

            # yfinance ì‹œì´ìœ¼ë¡œ ë³´ì •
            yf_mcap = info.get("marketCap")
            if yf_mcap:
                r["market_cap"] = yf_mcap
                r["market_cap_fmt"] = format_market_cap(yf_mcap)

            # float ratio ë³´ê°• ì‹œ ë³€ë™ì„± ì ìˆ˜ ì¬ê³„ì‚°
            if fr_val is not None:
                old_vol = r["volatility_score"]
                new_vol = old_vol * 0.8 + fr_s * 0.2
                r["volatility_score"] = round(new_vol, 1)
                old_total = r["total_score"]
                r["total_score"] = round(
                    old_total + (new_vol - old_vol) * 0.15, 1
                )
                r["total_score"] = min(100, r["total_score"])

            # í”Œë˜ê·¸ ì—…ë°ì´íŠ¸
            if fr_val is not None and fr_val < 0.5 and "ğŸ¯ Low Float" not in r.get("flags", []):
                r.setdefault("flags", []).append("ğŸ¯ Low Float")

            # ===== ìˆ ì´ììœ¨ =====
            short_pct = info.get("shortPercentOfFloat")
            if short_pct is not None:
                r["short_interest"] = round(short_pct * 100, 1)
                r["short_ratio"] = info.get("shortRatio")
                short_count += 1
                # ìˆìŠ¤í€´ì¦ˆ ë³´ë„ˆìŠ¤
                if short_pct >= 0.15 and r.get("accum_score", 0) >= 65:
                    r["total_score"] = min(100, r["total_score"] + 5)
                    if "ğŸ”¥ ìˆìŠ¤í€´ì¦ˆ ê°€ëŠ¥" not in r.get("flags", []):
                        r.setdefault("flags", []).append("ğŸ”¥ ìˆìŠ¤í€´ì¦ˆ ê°€ëŠ¥")
                elif short_pct >= 0.10:
                    if "ğŸ“ ìˆ ë¹„ì¤‘â†‘" not in r.get("flags", []):
                        r.setdefault("flags", []).append("ğŸ“ ìˆ ë¹„ì¤‘â†‘")

            # ===== ì‹¤ì  ë°œí‘œ ê²½ê³  =====
            try:
                earnings_ts = info.get("earningsTimestampStart") or info.get("earningsTimestamp")
                if earnings_ts:
                    earnings_date = datetime.fromtimestamp(earnings_ts)
                    days_until = (earnings_date - datetime.now()).days
                    if 0 <= days_until <= 14:
                        r["earnings_soon"] = True
                        r["earnings_days"] = days_until
                        r.setdefault("flags", []).append(f"ğŸ“… ì‹¤ì  D-{days_until}")
                        earnings_count += 1
                    elif -3 <= days_until < 0:
                        r["earnings_recent"] = True
                        r.setdefault("flags", []).append("ğŸ“… ì‹¤ì  ì™„ë£Œ")
            except Exception:
                pass

        results.sort(key=lambda x: x["total_score"], reverse=True)
        print(f"  âœ… ìƒì„¸ ì •ë³´ ë³´ê°• ì™„ë£Œ (ìˆë°ì´í„°:{short_count}ê°œ, ì‹¤ì ê²½ê³ :{earnings_count}ê°œ)")

    def run_full_scan(self):
        print("=" * 60)
        print("  ğŸ” ê¸‰ë“± ì˜ˆì¸¡ê¸° v4 - Low Cap US Stock Surge Detector")
        print("=" * 60)

        # ì¢…ëª© ìˆ˜ì§‘
        print("\nğŸ“‹ ì¢…ëª© ìˆ˜ì§‘ ì¤‘...")
        all_tickers, self.metadata = UniverseFetcher.get_universe()
        total_universe = len(all_tickers)

        # SPY í¬í•¨ ë²Œí¬ ë‹¤ìš´ë¡œë“œ
        download_list = ["SPY"] + all_tickers
        print(f"\nğŸ“¥ {total_universe}ì¢…ëª© + SPY ê°€ê²© ë°ì´í„° ì¼ê´„ ë‹¤ìš´ë¡œë“œ...\n")
        t0 = time.time()
        all_data = self._bulk_download(download_list)

        # SPY ë°ì´í„° ì¶”ì¶œ
        spy_df = all_data.pop("SPY", None)
        self.spy_close = spy_df["Close"] if spy_df is not None and not spy_df.empty else None
        if self.spy_close is not None:
            print(f"\n  âœ… SPY ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
        else:
            print(f"\n  âš ï¸ SPY ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")

        download_sec = time.time() - t0
        print(f"  ğŸ“Š ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {len(all_data)}ì¢…ëª© ({download_sec:.0f}ì´ˆ)")
        print(f"\nğŸ” {len(all_data)}ì¢…ëª© ê¸°ìˆ  ë¶„ì„ ì‹œì‘...\n")

        results = []
        failed = 0
        analyzed = 0

        for ticker, hist in all_data.items():
            analyzed += 1
            if analyzed % 200 == 0:
                print(f"  ğŸ“Š ë¶„ì„ ì§„í–‰: {analyzed}/{len(all_data)}...")
            try:
                r = self.analyze_stock(ticker, hist)
                if r:
                    results.append(r)
                    if r["total_score"] >= 65:
                        print(f"    ğŸ¯ {r['name'][:25]:>25s} | {r['total_score']:5.1f}ì  | {r['signal']} | {r['market_cap_fmt']}")
                else:
                    failed += 1
            except Exception:
                failed += 1

        elapsed = time.time() - t0
        print(f"\nâ±ï¸ ë¶„ì„ ì™„ë£Œ: {elapsed:.0f}ì´ˆ (ì„±ê³µ:{len(results)} ì‹¤íŒ¨:{failed})")

        # 1ì°¨ ì •ë ¬
        results.sort(key=lambda x: x["total_score"], reverse=True)

        # ì„¹í„° ìƒëŒ€ê°•ë„ ë³´ë„ˆìŠ¤
        self._add_sector_bonuses(results)

        # ìƒìœ„ ì¢…ëª© ìƒì„¸ ì •ë³´ ë³´ê°• (ìˆ ì´ììœ¨, ì‹¤ì  ê²½ê³  í¬í•¨)
        self._enrich_top_results(results, top_n=100)

        # ì¬ì •ë ¬
        results.sort(key=lambda x: x["total_score"], reverse=True)

        # ì‹œê·¸ë„ ì§€ì†ì„± & ì‹ ê·œ ì‹œê·¸ë„
        new_signals = self.signal_tracker.get_new_signals(results)
        for r in results:
            r["signal_days"] = self.signal_tracker.get_persistence(r["ticker"])
            r["is_new"] = r["ticker"] in new_signals

        # ê³¼ê±° ì ì¤‘ë¥ 
        hit_rates = self.signal_tracker.compute_hit_rates()

        # ì‹œê·¸ë„ ìŠ¤ëƒ…ìƒ· ì €ì¥
        self.signal_tracker.save_snapshot(results)

        self.results = results

        elapsed_total = time.time() - t0
        self.market_summary = {
            "total_analyzed": len(results),
            "total_universe": total_universe,
            "surge_imminent": len([r for r in results if r["total_score"] >= 78]),
            "accumulating": len([r for r in results if r["total_score"] >= 68]),
            "watchlist": len([r for r in results if r["total_score"] >= 55]),
            "avg_score": round(np.mean([r["total_score"] for r in results]), 1) if results else 0,
            "low_float_count": len([r for r in results if (r.get("float_ratio") or 1) < 0.5]),
            "high_vol_count": len([r for r in results if (r.get("volatility_score") or 0) >= 70]),
            "new_signal_count": len([r for r in results if r.get("is_new") and r["total_score"] >= 55]),
            "short_squeeze_count": len([r for r in results if r.get("short_interest") and r["short_interest"] >= 15]),
            "hit_rates": hit_rates,
            "scan_sec": round(elapsed_total),
            "updated_at": datetime.now(timezone(timedelta(hours=9))).strftime("%Y-%m-%d %H:%M KST"),
        }
        return results

    def save_results(self, path="data/analysis.json"):
        os.makedirs(os.path.dirname(path), exist_ok=True)

        # ë°ì´í„° ìµœì í™”: ìƒìœ„ 500ê°œ ìƒì„¸, ë‚˜ë¨¸ì§€ ìš”ì•½
        full_stocks = self.results[:500]
        minimal_stocks = []
        for r in self.results[500:]:
            minimal_stocks.append({
                "ticker": r["ticker"],
                "name": r["name"],
                "price": r["price"],
                "signal": r["signal"],
                "total_score": r["total_score"],
                "volatility_score": r.get("volatility_score"),
                "accum_score": r.get("accum_score"),
                "pattern_score": r.get("pattern_score"),
                "tech_score": r.get("tech_score"),
                "market_cap_fmt": r.get("market_cap_fmt"),
                "return_1d": r["return_1d"],
                "return_5d": r.get("return_5d"),
                "return_20d": r.get("return_20d"),
                "volume_ratio": r["volume_ratio"],
                "sector": r.get("sector", ""),
                "sparkline": r.get("sparkline"),
                "signal_days": r.get("signal_days", 0),
                "is_new": r.get("is_new", False),
            })

        out = {
            "version": "4.0",
            "focus": "low-cap-us-surge",
            "summary": self.market_summary,
            "stocks": full_stocks + minimal_stocks,
        }

        # JSON (readable)
        with open(path, "w", encoding="utf-8") as f:
            json.dump(out, f, ensure_ascii=False, indent=2)

        # JS (minified for browser)
        js = path.replace(".json", ".js")
        with open(js, "w", encoding="utf-8") as f:
            f.write("var STOCK_DATA = ")
            json.dump(out, f, ensure_ascii=False, separators=(',', ':'))
            f.write(";\n")

        json_size = os.path.getsize(path) / 1024 / 1024
        js_size = os.path.getsize(js) / 1024 / 1024
        print(f"ğŸ’¾ ì €ì¥: {path} ({json_size:.1f}MB) + {js} ({js_size:.1f}MB)")

    def build_telegram_msg(self, top_n=15):
        kst = timezone(timedelta(hours=9))
        now = datetime.now(kst)
        s = self.market_summary

        msg = f"ğŸ” *ê¸‰ë“± ì˜ˆì¸¡ ë¦¬í¬íŠ¸ v4*\n"
        msg += f"ğŸ“… {now.strftime('%Y-%m-%d %H:%M')} KST\n"
        msg += f"ğŸ¯ ë¯¸êµ­ ì†Œí˜•ì£¼ (ì‹œì´ < $2B)\n"
        msg += "â”" * 25 + "\n\n"
        msg += f"ğŸ“Š *ìŠ¤ìº” ê²°ê³¼* ({s['total_analyzed']}ì¢…ëª© ë¶„ì„)\n"
        msg += f"ğŸ”´ ê¸‰ë“±ì„ë°•: {s['surge_imminent']}ê°œ | ğŸŸ  ë§¤ì§‘: {s['accumulating']}ê°œ | ğŸŸ¡ ê´€ì‹¬: {s['watchlist']}ê°œ\n"
        msg += f"ğŸ¯ Low Float: {s['low_float_count']}ê°œ | ğŸŒ‹ ê³ ë³€ë™: {s['high_vol_count']}ê°œ\n"
        msg += f"ğŸ†• ì‹ ê·œì‹œê·¸ë„: {s.get('new_signal_count', 0)}ê°œ | ğŸ“ ìˆìŠ¤í€´ì¦ˆí›„ë³´: {s.get('short_squeeze_count', 0)}ê°œ\n"

        # ì ì¤‘ë¥  í‘œì‹œ
        hr = s.get("hit_rates")
        if hr:
            msg += "\nğŸ“ˆ *ê³¼ê±° ì ì¤‘ë¥ *\n"
            for period, data in hr.items():
                msg += f"  {period}: 10%â†‘ {data['hit_10pct']}% | 5%â†‘ {data['hit_5pct']}% | í‰ê·  {data['avg_return']:+.1f}% ({data['total']}ê±´)\n"

        msg += "\n"

        surge = [r for r in self.results if r["total_score"] >= 78]
        if surge:
            msg += "ğŸ”´ *ê¸‰ë“± ì„ë°•*\n\n"
            for r in surge[:5]:
                new_tag = "ğŸ†• " if r.get("is_new") else ""
                days_tag = f"[{r.get('signal_days', 0)}ì¼]" if r.get("signal_days", 0) > 1 else ""
                msg += f"*{new_tag}{r['name']}* ({r['ticker']}) {r['total_score']}ì  {days_tag}\n"
                msg += f"  ì‹œì´:{r['market_cap_fmt']} | Vol:{r.get('volatility_score', '-')} Acc:{r['accum_score']} Pat:{r['pattern_score']} Tech:{r['tech_score']}\n"
                if r.get("short_interest"):
                    msg += f"  ìˆë¹„ì¤‘: {r['short_interest']:.1f}%\n"
                for fl in r.get("flags", [])[:2]:
                    msg += f"  {fl}\n"
                msg += "\n"

        accum = [r for r in self.results if 68 <= r["total_score"] < 78]
        if accum:
            msg += "ğŸŸ  *ë§¤ì§‘ ì§„í–‰*\n\n"
            for r in accum[:7]:
                new_tag = "ğŸ†• " if r.get("is_new") else ""
                msg += f"*{new_tag}{r['name']}* ({r['ticker']}) {r['total_score']}ì  | 5D:{r['return_5d']:+.1f}% | {r['market_cap_fmt']}\n"
                if r.get("flags"):
                    msg += f"  {r['flags'][0]}\n"

        msg += "\n" + "â”" * 25 + "\nâš ï¸ ê¸°ìˆ ì  ë¶„ì„ ì°¸ê³ ìë£Œ. íˆ¬ì íŒë‹¨ì€ ë³¸ì¸ ì±…ì„."
        return msg

    def send_telegram(self, message):
        if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_ID:
            print("\nğŸ“± í…”ë ˆê·¸ë¨ ë¯¸ì„¤ì • - ë¯¸ë¦¬ë³´ê¸°:\n")
            print(message)
            return

        base = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}"
        try:
            me = requests.get(f"{base}/getMe", timeout=10)
            if me.status_code != 200:
                print(f"âŒ í…”ë ˆê·¸ë¨ ë´‡ í† í° ë¬´íš¨: {me.text}")
                print("   â†’ BotFatherì—ì„œ í† í°ì„ ì¬í™•ì¸í•˜ê³  GitHub Secretsë¥¼ ì—…ë°ì´íŠ¸í•˜ì„¸ìš”")
                return
            print(f"âœ… ë´‡ í™•ì¸: {me.json().get('result', {}).get('username', '?')}")
        except Exception as e:
            print(f"âŒ í…”ë ˆê·¸ë¨ ì—°ê²° ì‹¤íŒ¨: {e}")
            return

        url = f"{base}/sendMessage"
        parts, m = [], message
        while m:
            if len(m) <= 4096:
                parts.append(m)
                break
            i = m.rfind('\n', 0, 4096)
            if i == -1:
                i = 4096
            parts.append(m[:i])
            m = m[i:]
        for p in parts:
            try:
                r = requests.post(url, json={
                    "chat_id": TELEGRAM_CHAT_ID,
                    "text": p,
                    "parse_mode": "Markdown",
                    "disable_web_page_preview": True,
                }, timeout=15)
                if r.status_code == 200:
                    print("âœ… ì „ì†¡ ì™„ë£Œ!")
                else:
                    print(f"âš ï¸ Markdown ì „ì†¡ ì‹¤íŒ¨ ({r.status_code}), ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œ ì¬ì‹œë„...")
                    r2 = requests.post(url, json={
                        "chat_id": TELEGRAM_CHAT_ID,
                        "text": p.replace("*", "").replace("_", ""),
                        "disable_web_page_preview": True,
                    }, timeout=15)
                    print("âœ… ì „ì†¡ ì™„ë£Œ (í…ìŠ¤íŠ¸)" if r2.status_code == 200 else f"âŒ ì‹¤íŒ¨: {r2.text}")
            except Exception as e:
                print(f"âŒ ì˜¤ë¥˜: {e}")


def main():
    p = PreSurgePredictor()
    results = p.run_full_scan()
    if not results:
        print("âŒ ê²°ê³¼ ì—†ìŒ")
        return
    p.save_results("data/analysis.json")
    p.send_telegram(p.build_telegram_msg())

    print("\n" + "=" * 60)
    print("  ğŸ† TOP 10 ê¸‰ë“± í›„ë³´ (ë¯¸êµ­ ì†Œí˜•ì£¼)")
    print("=" * 60)
    for i, r in enumerate(results[:10], 1):
        new_tag = "ğŸ†•" if r.get("is_new") else "  "
        days = f"[{r['signal_days']}d]" if r.get("signal_days", 0) > 1 else "     "
        print(f"  {new_tag} {i:2d}. {r['name']:>25s} | {r['total_score']:5.1f}ì  | {r['market_cap_fmt']:>8s} | {days} | {r['signal']}")
        for fl in r.get("flags", []):
            print(f"         {fl}")


if __name__ == "__main__":
    main()
